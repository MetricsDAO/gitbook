# SQL, Aggregated

{% embed url="https://www.youtube.com/watch?v=OAxQ-pOFf_E" %}
Replay of Segment 2 live session.
{% endembed %}



Great! We can calculate some stats and metrics across our result set. But, we often want to see what's happening _within_ the set, both over time and across groups. Enter `GROUP BY`.

## GROUP BY

Let's build on the code we used in segment 1, specifically the opensea sales:

* [https://app.flipsidecrypto.com/velocity/queries/75e7a743-09e3-4252-b33e-4ca6f5921dab](https://app.flipsidecrypto.com/velocity/queries/75e7a743-09e3-4252-b33e-4ca6f5921dab)

In that example we just used `where currency = ETH`, and got was most of the sales for June... but we don't just want "most" because that's a bit too convenient an approach.

So, instead of excluding everything and just filtering to ETH, we can instead use `GROUP BY` to `SUM` within groups:

```sql
SELECT 
    currency_symbol,
    SUM(platform_fee) AS total_platform_fee,
    SUM(platform_fee_usd) AS total_platform_fees_usd
FROM ethereum.core.ez_nft_sales
WHERE block_timestamp::DATE BETWEEN '2022-06-01' AND '2022-06-30'
    AND platform_name = 'opensea'
    GROUP BY 1
    ORDER BY 1 DESC;
```

[Link to Query](https://app.flipsidecrypto.com/velocity/queries/5212ef91-5405-4d63-a4ec-38a6628e936e)

{% hint style="info" %}
**Using Visualizations in Our Analytical Process**

As mentioned, presentation is not the only purpose of visualization tools. They can seriously help us in our analytical process, and can spark curiosity as we work through data.&#x20;
{% endhint %}

Fork the above query and make a donut chart with the results, it should look something like this:

![](<../../../.gitbook/assets/Screenshot 2022-08-10 at 09-47-25 Flipside Crypto.png>)

It's pretty clear ETH (and WETH) is the dominant currency on OpenSea, capturing 99.3% of fee revenue in June 2022. But, we can still dive in and explore the "rest" of the data to see if there's anything interesting in there.

Hide ETH and WETH by clicking them on the legend, so we're left with just the other tokens. Notice anything of interest?

For me, the fact that GALA is 2x USDC stands out, especially because I don't know what GALA is...

<details>

<summary>Steps one might take here:</summary>

* Find some transactions where GALA is the currency

`select * from ethereum.core.ez_nft_sales where currency_symbol = 'GALA' limit 10;` ([query](https://app.flipsidecrypto.com/velocity/queries/eb181103-3279-4727-b819-ae70d557af54))

* Grab any tx hash from there and look at it on [Etherscan](https://etherscan.io)
* We can look this up in the `fact_transactions` table, as well, to see how the full transaction is structured (hint: it's the `tx_json` column. I would just copy that full thing and look at it in a nice structured form using something [like this](https://jsonformatter.org/).
* Take a look at the JSON and etherscan side-by-side! Compare the high-level info, maybe look at the logs for where the details - the meat of the transaction - live.
* That nice "Transaction Action" part (screenshot below)? Consider that equivalent to the `ez_` tables. All the transaction information is there, like with the `fact_transactions` table, but sometimes we just want the clean-cut action.
* The point of this is to get used to seeing the full scale of an Ethereum transaction. There's a lot we could extract from that JSON, it's all up to what your analysis requires.
* We'll get into parsing JSONs later - no need to get overwhelmed by this!

<img src="../../../.gitbook/assets/Screen Shot 2022-08-10 at 10.44.00.png" alt="" data-size="original">

</details>

Back to the SQL.

In this case, `GROUP BY 1` indicates that the grouping should happen on the first column, which is `currency_symbol`. In a most basic sense, group by "squishes" results into the proper groups. So, wherever `currency_symbol = 'ETH'`, those records will be summed up together. Using `GROUP BY` over our prior method means we are not excluding the records where the currency is not ETH. The fees generated by those sales are included in records of their own category!

But, still, we can get more granular and begin to look at patterns.

### HAVING

We can filter our aggregated results, but not with `WHERE` ! That will apply to the query, still, in that the parameters within the where clause impact the result set.

We then use `GROUP BY` and aggregation functions to compute something over that result set. But, what if we wanted to limit those results to exclude outliers, or to hone in on a specific band of volume. We can filter the aggregated results with `HAVING`.

If you ran the above code, you'll notice a lot of small-dollar, random, or null values for some of the currencies. We may want to exclude these from the analysis, if deemed appropriate.

```sql
SELECT 
    DATE_TRUNC('day', block_timestamp) AS _date,
    currency_symbol,
    SUM(platform_fee) AS total_platform_fee,
    SUM(platform_fee_usd) AS total_platform_fees_usd
FROM ethereum.core.ez_nft_sales
WHERE block_timestamp::DATE BETWEEN '2022-06-01' AND '2022-06-30'
    AND platform_name = 'opensea'
    GROUP BY 1, 2
    HAVING total_platform_fees_usd > 1000
    ORDER BY 1, 4 DESC;
```

[Link to Query](https://app.flipsidecrypto.com/velocity/queries/0b226f07-6b25-4696-b631-62327a3adabb) / [Viz 1](https://velocity-app.flipsidecrypto.com/velocity/visuals/855568e3-a60d-46a0-af57-850f05d7d327/0b226f07-6b25-4696-b631-62327a3adabb) / [Viz 2](https://velocity-app.flipsidecrypto.com/velocity/visuals/c9a5dfb9-b93f-4b5d-b2b8-1b67250aca98/0b226f07-6b25-4696-b631-62327a3adabb)

Notice here we use `GROUP BY 1, 2` - per above we should be able to infer that this is&#x20;

* creating a group based on date
* creating a group based on currency, within each date

$1,000 was selected fairly arbitrarily, it's up to the analyst and the purpose behind setting these parameters!

{% hint style="warning" %}
****[**Order of Operations**](https://mode.com/sql-tutorial/sql-having/#query-clause-order)****

Confused about what goes where? Not a problem, there's a lot to keep track of! Of the concepts we've learned _so far_, here's the order of operations for how you should structure your query:

1. `SELECT`
2. `FROM`
3. `WHERE`
4. `GROUP BY`
5. `HAVING`
6. `ORDER BY`

Think about it in clusters:

* First we have to get the data and create our result set `SELECT FROM WHERE`
* then we might want to do something to that result set- transform it in some way `GROUP BY HAVING`
* finally, we might want to stay organized so we`ORDER BY`
{% endhint %}

## [DATE\_TRUNC](https://docs.snowflake.com/en/sql-reference/functions/date\_trunc.html)

We can even use this `GROUP BY` on dates! Say we want to visualize these sales over time, whether it be day, week, quarter, etc. We can use a special date & time function to truncate the `block_timestamp` to a desired precision.

Let's revise the above query to look at daily fee volume on OpenSea:

```sql
SELECT 
    DATE_TRUNC('week', block_timestamp) as _date,
    currency_symbol,
    SUM(platform_fee) AS total_platform_fee,
    SUM(platform_fee_usd) AS total_platform_fees_usd
FROM ethereum.core.ez_nft_sales
WHERE block_timestamp::DATE BETWEEN '2022-01-01' AND '2022-06-30'
    AND platform_name = 'opensea'
    GROUP BY 1, 2
    ORDER BY 1, 4 DESC;
```

[Link to Query](https://app.flipsidecrypto.com/velocity/queries/edc9c625-11e0-42a7-95bb-48fe67475191)

`DATE_TRUNC` is quite dynamic and can help us look at a wide variety of time slices, using any of the supported [date / time parts](https://docs.snowflake.com/en/sql-reference/functions-date-time.html#label-supported-date-time-parts)!

## CASE Statements

We can replace data if we don't like it. No, not in the manipulate the numbers sense! In our fee analysis thus far, we have some 20+ currencies accounting for <1% of OpenSea fee revenue and that makes for a really messy outcome. So, let's lump those all into an "other group" by replacing everything that we don't want from within `currency_symbol`.

CASE statements are if conditionals, but we use the keyword `WHEN` instead of `IF`.

* _when not where - this can be easy to mix up in your head early on!_

The basic structure of a case statement is:

```sql
CASE -- declare the start of a case statement
  WHEN <conditional statement> THEN <outcome> -- if the conditional statement evaluates to true, the <outcome> will be used
  WHEN <conditional statement> THEN <outcome>
  ELSE <outcome> -- optional line to include as a "catch-all"
END AS <alias> -- declare the end of a case statement and alias the column name
```

The result of a case statement is a column, hence the `<alias>`, but what is happening? We are replacing the contents of a column, based on some parameters.

In our example, we want to keep a select few currencies, and change every other currency to "Other"

```sql
SELECT 
    DATE_TRUNC('day', block_timestamp) AS _date,
    CASE
  	WHEN currency_symbol = 'ETH' THEN currency_symbol
  	WHEN currency_symbol = 'WETH' THEN currency_symbol
  	WHEN currency_symbol = 'USDC' THEN currency_symbol
  	ELSE 'Other'
    END AS currency_symbol,
    SUM(platform_fee) AS total_platform_fee,
    SUM(platform_fee_usd) AS total_platform_fees_usd
FROM ethereum.core.ez_nft_sales
WHERE block_timestamp::DATE BETWEEN '2022-06-01' AND '2022-06-30'
    AND platform_name = 'opensea'
    GROUP BY 1, 2
    ORDER BY 1, 4 DESC;
```

[Link to Query](https://app.flipsidecrypto.com/velocity/queries/cd352c3a-bea2-435f-9930-9832aa9d81a2)

Notice above, the outcome of `WHEN currency_symbol = desired currency` is the column `currency_symbol` while the outcome for `ELSE` is a string `'Other'`. In plain terms, we're saying when currency\_symbol is ETH, WETH, or USDC take the value in the column. For everything else, use this string, `'Other'`, instead.

## Common Table Expressions (CTEs)

Sometimes we need data in multiple formats, will need to use it multiple times and in different way or we need to get data from somewhere, based on a table elsewhere. We can create a temporary _view_ within our query with a CTE.

Think of the CTE as a query in and of itself where a result set is returned. We can see exactly what this result would be if we were to highlight and run the query between the parenteses (if you do, **add a limit** or you will be waiting for a lot of records for a long time).

This result set can be thought of as a table that exists only while the query is running. Thus, we can `SELECT FROM` the CTE using whatever name we choose as its alias, in the below case `opensea_sales`.

<pre class="language-sql"><code class="lang-sql">WITH
opensea_sales AS (
<strong>    SELECT
</strong>        *
    FROM ethereum.core.ez_nft_sales
    WHERE block_timestamp::DATE BETWEEN '2022-06-01' AND '2022-06-30'
        AND platform_name = 'opensea'
)
SELECT
    DATE_TRUNC('day', block_timestamp) as _date,
    CASE
  	WHEN currency_symbol = 'ETH' THEN 'ETH'
  	WHEN currency_symbol = 'WETH' THEN 'WETH'
  	WHEN currency_symbol = 'USDC' THEN 'USDC'
  	ELSE 'Other'
    END AS currency_symbol,
    SUM(platform_fee) AS total_platform_fee,
    SUM(platform_fee_usd) AS total_platform_fees_usd
FROM opensea_sales
GROUP BY 1, 2
ORDER BY 1, 4 DESC;</code></pre>

[Link to Query](https://app.flipsidecrypto.com/velocity/queries/1d75c38c-cea0-4bc5-85b6-d94a3bcc7a21)

{% hint style="info" %}
**Structure**

There's a lot of structure and syntax to keep track of, right?

CTEs begin with the keyword `WITH`. This is only necessary to start the sequency of CTEs, each subsequent CTE simply follows `<alias> as (<query>)`. _(If you watched the video you'll see how many times I forgot to add the as ðŸ˜…, it happens)_

The only other thing to remember is that each is comma separated, so:

`WITH`&#x20;

&#x20; `<alias> as ( SELECT statement ),`

&#x20; `<alias 2> as ( SELECT statement 2 ),`

&#x20; `...`

&#x20; `<alias n> as ( SELECT statement n)`

`SELECT * FROM <alias>`

Notice how we have a final `SELECT` outside any CTE. This is a must! This is the last query that will return your ultimate result set.
{% endhint %}

CTE Example 2: Bringing in \~other data\~ from the prices table.

Let's continue with the OpenSea fee analysis and compare the price of ETH against OpenSea fee revenue.

<pre class="language-sql" data-line-numbers><code class="lang-sql"><strong>WITH prices AS (
</strong>  SELECT
      date_trunc('day', hour) AS _date,
      AVG(price) AS avg_price_usd
  FROM ethereum.core.fact_hourly_token_prices
  WHERE _date BETWEEN '2022-01-01' AND '2022-06-30'
  	AND symbol = 'WETH'
  GROUP BY 1
),
openfee AS (
  SELECT 
    DATE_TRUNC('day', block_timestamp) AS _date,
    SUM(platform_fee) AS total_platform_fee,
    SUM(platform_fee_usd) AS total_platform_fees_usd
FROM ethereum.core.ez_nft_sales
WHERE block_timestamp::DATE BETWEEN '2022-01-01' AND '2022-06-30'
    AND platform_name = 'opensea'
    GROUP BY 1
)
SELECT
    o._date,
    o.total_platform_fees_usd,
    p.avg_price_usd
FROM openfee o
    LEFT JOIN prices p USING (_date)
ORDER BY 1, 3 DESC</code></pre>

[Link to Query](https://app.flipsidecrypto.com/velocity/queries/6f39245b-2d01-4c1f-88b1-29365cfc5d68)

We are able to bring the data from these CTEs together in the final query using a `JOIN`. If you are unfamilair with how these work, just scroll down!

But, while we're in the CTE section, 1 more thing to add. Yes, data from a CTE can be joined in a subsequent CTE. In the above example, we query and aggregate OpenSea fee data in the `openfee` CTE. However, this could have still been parceled out in 2 steps, like in the first CTE example, where a first CTE selects the transaction records (`opensea_sales` 2 code blocks up) and the `openfee` aggregation could be a subsequent CTE that selects from `opensea_sales` instead of from `ez_nft_sales`.

### Dive Deeper

{% embed url="https://www.geeksforgeeks.org/cte-in-sql/" %}

{% embed url="https://chartio.com/resources/tutorials/using-common-table-expressions/" %}

## Joins

So we just introduced something wholly new - working with data from multiple sources (tables). How did we combine the disparate result sets into one? That happens with line 25, above, where we reference `LEFT JOIN x USING (y)`.

{% hint style="info" %}
You may also be used to `LEFT JOIN x ON a.y = b.y`, the keyword `USING` is supported by Snowflake and is a bit more streamlined to use _when both columns use the same name or alias._
{% endhint %}

Here we are joining on a common date, but you can take data from a wide variety of columns

* Maybe in `ez_dex_swaps` we join on
  * pool name / contract
  * token name / contract
  * origin from address - we can compare the activity from an address across dex swaps and nft sales!
* Or if we're working with raw transaction data and need some labels, an analyst can use data from other tables to enhance the outcome
  * `dim_dex_liquidity_pools`
  * `dim_contracts`&#x20;
  * `dim_hourly_token_prices`

There are a number of types of joins, but the most common one you'll likely use for now is a `LEFT JOIN`.

### LEFT JOIN

In this join, the left table is the one referenced first. In the below example, `ez_dex_swaps` is left and `dim_hourly_token_prices` is right.

```sql
SELECT
    <columns>
FROM ethereum.core.ez_dex_swaps
    LEFT JOIN ethereum.core.dim_hourly_token_prices ON <common column>
```

Declaring the type of join is effectively deciding what data overlap you want to keep. In a `LEFT JOIN` we are preserving **all rows** in the left table, and only joining overlaps from the right table.

The below tool does the best job, that I have found so far, at demonstrating what happens with data from two sources when they are joined together using different methods.

{% embed url="https://joins.spathon.com/" %}

### Joining on Multiple Columns

You can join tables using many columns! An example of this might be `date` and `address`. We developed an example on this in the video where it might make sense to track NFT mints and subsequent sales by joining the `ez_nft_mints` and `ez_nft_sales` columns on both date and nft contract address.

{% code lineNumbers="true" %}
```sql
WITH 
sales AS (
  SELECT 
      date_trunc('d', block_timestamp) AS _date,
      nft_address,
      SUM(price) AS total_eth_sale
  FROM ethereum.core.ez_nft_sales
  WHERE block_timestamp > CURRENT_DATE - 30
  GROUP BY 1, 2
),
mints AS (
  SELECT
      date_trunc('d', block_timestamp) AS _date,
      nft_address,
      SUM(mint_price_eth) AS total_eth_mint
  FROM ethereum.core.ez_nft_mints
  WHERE block_timestamp > CURRENT_DATE - 30
  GROUP BY 1,2
)

SELECT
    m._date, -- _date exists in both CTEs so we explicitly declare m._date
    m.nft_address,
    m.total_eth_mint,
    s.total_eth_sale
FROM mints m -- here we alias the mints CTE as just m for simplicity
  LEFT JOIN sales s
    ON m._date=s._date AND m.nft_address=s.nft_address
ORDER BY 1, 3 DESC
```
{% endcode %}

[Link to Query](https://app.flipsidecrypto.com/velocity/queries/c1902224-9a7f-4da3-a9f8-ce9c3fe83c03)

{% hint style="info" %}
This was written out of a community question and is not refined or polished. The linked query goes on to further join contract labels to add some readability to the result.

Feel free to fork it and try some analysis of your own with this as a base!
{% endhint %}

**What's happening in this query?**

1. On lines `2-10` we declare the first CTE that aggregates NFT sales over the past 30 days, from `ez_nft_sales`.
2. Our second CTE on lines `11-19` queries the `ez_nft_mints` table, aggregating total ETH minted per NFT drop in the past 30 days
3. The final query in lines `21-29` combines the data from each of these with `mints` as the **left** table.

Recall from the [visual join reference](https://joins.spathon.com/) that everything in the left table is preserved, while only matching overlaps from the right table are brought into our final dataset. So, in plain terms, what we are doing here is taking all NFT mints in the past 30 days, and by joining on date and nft address, we are including subsequent secondary market sales _for just those addresses in the mint column_.

### Dive Deeper

{% embed url="https://mode.com/sql-tutorial/sql-joins/" %}
